{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4847140e",
   "metadata": {},
   "source": [
    "https://devblogs.microsoft.com/foundry/azure-ai-mem0-integration/\n",
    "\n",
    "\n",
    "TL;DR\n",
    "Learn how to integrate Mem0 with Azure AI Search and Azure OpenAI to create AI applications with persistent memory. This tutorial provides code examples for setting up a memory layer using Azure services and demonstrates how to build a travel planning assistant that remembers user preferences across conversations.\n",
    "\n",
    "Introduction\n",
    "One of the key limitations of most AI systems is their inability to maintain context beyond a single session. This lack of memory significantly impacts the quality of user interactions, often requiring users to repeat information they’ve already provided. Enter Mem0, a powerful memory layer designed specifically for AI applications.\n",
    "\n",
    "In this guide, we’ll explore how to integrate Mem0 with Azure AI services to create AI applications with persistent memory. We’ll cover:\n",
    "\n",
    "Setting up Mem0 with Azure AI Search and Azure OpenAI\n",
    "Basic memory operations (storing, retrieving, and searching memories)\n",
    "Building a practical travel planning assistant that remembers user preferences\n",
    "Prerequisites\n",
    "Azure OpenAI account with access to model deployments\n",
    "Azure AI Search service\n",
    "Python environment with required packages\n",
    "First, let’s install the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95a7abd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mem0ai in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (0.1.104)\n",
      "Requirement already satisfied: python-dotenv in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: openai in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (1.84.0)\n",
      "Requirement already satisfied: azure-identity in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (1.23.0)\n",
      "Requirement already satisfied: azure_search in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (1.0.0b2)\n",
      "Requirement already satisfied: azure_search_documents in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (11.5.2)\n",
      "Requirement already satisfied: posthog>=3.5.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from mem0ai) (4.2.0)\n",
      "Requirement already satisfied: pydantic>=2.7.3 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from mem0ai) (2.11.5)\n",
      "Requirement already satisfied: pytz>=2024.1 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from mem0ai) (2025.2)\n",
      "Requirement already satisfied: qdrant-client>=1.9.1 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from mem0ai) (1.14.2)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.31 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from mem0ai) (2.0.41)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from pydantic>=2.7.3->mem0ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from pydantic>=2.7.3->mem0ai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from pydantic>=2.7.3->mem0ai) (0.4.1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure-identity) (1.34.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure-identity) (45.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure-identity) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: msrest>=0.6.10 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure_search) (0.7.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure-core>=1.31.0->azure-identity) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: azure-common>=1.1 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure_search_documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from azure_search_documents) (0.7.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from msrest>=0.6.10->azure_search) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from posthog>=3.5.0->mem0ai) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from posthog>=3.5.0->mem0ai) (2.2.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from qdrant-client>=1.9.1->mem0ai) (1.72.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from qdrant-client>=1.9.1->mem0ai) (2.2.6)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from qdrant-client>=1.9.1->mem0ai) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from qdrant-client>=1.9.1->mem0ai) (6.31.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client>=1.9.1->mem0ai) (310)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai) (4.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure_search) (3.2.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from sqlalchemy>=2.0.31->mem0ai) (3.2.2)\n",
      "Requirement already satisfied: colorama in c:\\fy25\\aoai\\mem0\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mem0ai python-dotenv openai azure-identity azure_search azure_search_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d33cc",
   "metadata": {},
   "source": [
    "Setting Up Your Azure Environment\n",
    "To get started, you’ll need to configure your Azure environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ad1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mem0 import Memory\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Load Azure OpenAI configuration\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME\")\n",
    "\n",
    "# Load Azure AI Search configuration\n",
    "SEARCH_SERVICE_ENDPOINT = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "SEARCH_SERVICE_API_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "SEARCH_SERVICE_NAME = \"kmpzzcj6ybivvm-search\"\n",
    "\n",
    "# Create Azure OpenAI client\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-10-21\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9586a",
   "metadata": {},
   "source": [
    "Basic Memory Operations with Mem0 and Azure AI Search\n",
    "Let’s start with a simple example demonstrating how to store and retrieve memories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c45f9fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem0 initialized with Azure AI Search\n"
     ]
    }
   ],
   "source": [
    "# Configure Mem0 with Azure AI Search\n",
    "memory_config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"azure_ai_search\",\n",
    "        \"config\": {\n",
    "            \"service_name\": SEARCH_SERVICE_NAME,\n",
    "            \"api_key\": SEARCH_SERVICE_API_KEY,\n",
    "            \"collection_name\": \"memories\",\n",
    "            \"embedding_model_dims\": 3072,\n",
    "        },\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"azure_openai\",\n",
    "        \"config\": {\n",
    "            \"model\": AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME,\n",
    "            \"embedding_dims\": 3072,\n",
    "            \"azure_kwargs\": {\n",
    "                \"api_version\": \"2024-10-21\",\n",
    "                \"azure_deployment\": AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME,\n",
    "                \"azure_endpoint\": AZURE_OPENAI_ENDPOINT,\n",
    "                \"api_key\": AZURE_OPENAI_API_KEY,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"azure_openai\",\n",
    "        \"config\": {\n",
    "            \"model\": AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"azure_kwargs\": {\n",
    "                \"azure_deployment\": AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "                \"api_version\": \"2024-10-21\",\n",
    "                \"azure_endpoint\": AZURE_OPENAI_ENDPOINT,\n",
    "                \"api_key\": AZURE_OPENAI_API_KEY,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"version\": \"v1.1\",\n",
    "}\n",
    "\n",
    "# Initialize memory\n",
    "memory = Memory.from_config(memory_config)\n",
    "print(\"Mem0 initialized with Azure AI Search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa838a",
   "metadata": {},
   "source": [
    "The configuration above sets up:\n",
    "\n",
    "1) Vector Store: Using Azure AI Search to store and retrieve vectors\n",
    "2) Embedder: Using Azure OpenAI to generate embeddings for semantic search\n",
    "3) LLM: Using Azure OpenAI for language model capabilities\n",
    "Storing Memories\n",
    "With Mem0, you can store three types of memories:\n",
    "\n",
    "1. Simple statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c82f9286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.add(\n",
    "    \"I enjoy hiking in national parks and taking landscape photos.\",\n",
    "    user_id=\"demo_user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89572c63",
   "metadata": {},
   "source": [
    "2. Conversations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b4221f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': []}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, I'm interested in planning a relaxing holiday.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Great! Do you have a destination in mind or would you like some suggestions?\"},\n",
    "    {\"role\": \"user\", \"content\": \"I'd like some suggestions for peaceful places to visit and local attractions.\"}\n",
    "]\n",
    "memory.add(conversation, user_id=\"demo_user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf418dc3",
   "metadata": {},
   "source": [
    "3. Memories with metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec8f852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': []}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.add(\n",
    "    \"I prefer window seats on long flights and usually bring my own headphones.\",\n",
    "    user_id=\"demo_user\",\n",
    "    metadata={\"category\": \"travel_preferences\", \"importance\": \"medium\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7155d6",
   "metadata": {},
   "source": [
    "**Searching Memories**\n",
    "\n",
    "When you need to retrieve relevant memories, you can use the **search** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dee55a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Interested in planning a relaxing holiday (Score: 0.6246)\n",
      "2. Prefers window seats on long flights (Score: 0.5978)\n",
      "3. Usually brings own headphones on flights (Score: 0.5915)\n"
     ]
    }
   ],
   "source": [
    "search_results = memory.search(\n",
    "    \"What are this user's travel plans?\",\n",
    "    user_id=\"demo_user\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for i, result in enumerate(search_results['results'], 1):\n",
    "    print(f\"{i}. {result['memory']} (Score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a88cea",
   "metadata": {},
   "source": [
    "This will return memories sorted by relevance to the query, along with their similarity scores.\n",
    "\n",
    "Retrieving All Memories\n",
    "You can also retrieve all memories for a user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "587a8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memories: 6\n"
     ]
    }
   ],
   "source": [
    "all_memories = memory.get_all(user_id=\"demo_user\")\n",
    "print(f\"Total memories: {len(all_memories['results'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf6c10",
   "metadata": {},
   "source": [
    "**Building a Travel Planning Assistant with Memory**\n",
    "\n",
    "Now, let’s create a more practical example: a London travel planning assistant that remembers user preferences across conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aed089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TravelAssistant:\n",
    "    def __init__(self, user_id):\n",
    "        \"\"\"Initialize travel assistant with memory for a specific user\"\"\"\n",
    "        self.user_id = user_id\n",
    "\n",
    "        # Configure memory for travel planning\n",
    "        memory_config = {\n",
    "            \"vector_store\": {\n",
    "                \"provider\": \"azure_ai_search\",\n",
    "                \"config\": {\n",
    "                    \"service_name\": SEARCH_SERVICE_NAME,\n",
    "                    \"api_key\": SEARCH_SERVICE_API_KEY,\n",
    "                    \"collection_name\": \"travel_memories\",\n",
    "                    \"embedding_model_dims\": 3072,\n",
    "                    \"compression_type\": \"binary\",\n",
    "                },\n",
    "            },\n",
    "            \"llm\": {\n",
    "                \"provider\": \"azure_openai\",\n",
    "                \"config\": {\n",
    "                    \"model\": AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_tokens\": 800,\n",
    "                    \"azure_kwargs\": {\n",
    "                        \"azure_deployment\": AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "                        \"api_version\": \"2024-10-21\",\n",
    "                        \"azure_endpoint\": AZURE_OPENAI_ENDPOINT,\n",
    "                        \"api_key\": AZURE_OPENAI_API_KEY,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            \"embedder\": {\n",
    "                \"provider\": \"azure_openai\",\n",
    "                \"config\": {\n",
    "                    \"model\": AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME,\n",
    "                    \"embedding_dims\": 3072,\n",
    "                    \"azure_kwargs\": {\n",
    "                        \"api_version\": \"2024-10-21\",\n",
    "                        \"azure_deployment\": AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME,\n",
    "                        \"azure_endpoint\": AZURE_OPENAI_ENDPOINT,\n",
    "                        \"api_key\": AZURE_OPENAI_API_KEY,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            \"version\": \"v1.1\",\n",
    "        }\n",
    "\n",
    "        self.memory = Memory.from_config(memory_config)\n",
    "        self.azure_client = azure_openai_client\n",
    "        print(f\"Travel Assistant initialized for user {user_id}\")\n",
    "\n",
    "    def get_response(self, query, memory_context=True):\n",
    "        \"\"\"Get response from Azure OpenAI with memory context\"\"\"\n",
    "        # Retrieve relevant memories if enabled\n",
    "        memory_text = \"\"\n",
    "        if memory_context:\n",
    "            memories = self.memory.search(query, user_id=self.user_id)\n",
    "            if 'results' in memories and memories['results']:\n",
    "                memory_text = \"\\n\\nRelevant information from previous conversations:\\n\"\n",
    "                for i, mem in enumerate(memories['results'][:5], 1):\n",
    "                    memory_text += f\"{i}. {mem['memory']}\\n\"\n",
    "                print(f\"Including {len(memories['results'][:5])} memories in context\")\n",
    "            else:\n",
    "                print(\"No relevant memories found\")\n",
    "\n",
    "        # Construct messages with system prompt and memory context\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful travel assistant for London travel planning. \"\n",
    "                           \"Be concise, specific, and helpful. Refer to the user by name when appropriate. \"\n",
    "                           \"Recommend specific places when relevant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{query}\\n{memory_text}\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Get response from Azure OpenAI\n",
    "        response = self.azure_client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=800,\n",
    "        )\n",
    "\n",
    "        # Extract response content\n",
    "        response_content = response.choices[0].message.content\n",
    "\n",
    "        # Store the conversation in memory\n",
    "        conversation = [\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            {\"role\": \"assistant\", \"content\": response_content}\n",
    "        ]\n",
    "        self.memory.add(conversation, user_id=self.user_id)\n",
    "\n",
    "        return response_content\n",
    "\n",
    "    def verify_memories(self):\n",
    "        \"\"\"Verify what memories have been stored\"\"\"\n",
    "        all_memories = self.memory.get_all(user_id=self.user_id)\n",
    "        print(f\"\\n===== STORED MEMORIES ({len(all_memories['results'])}) =====\")\n",
    "        for i, memory in enumerate(all_memories['results'], 1):\n",
    "            print(f\"{i}. {memory['memory']}\")\n",
    "        print(\"==============================\\n\")\n",
    "        return all_memories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b89f9",
   "metadata": {},
   "source": [
    "**Using the Travel Assistant**\n",
    "\n",
    "Now, let’s put our travel assistant to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a60a8efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel Assistant initialized for user suresh_london_2025\n",
      "User: Hi, my name is Suresh. I'm planning a business trip to London next month for about 5 days.\n",
      "Assistant: Hi Suresh! That sounds exciting. For your business trip to London, here are a few tips and recommendations:\n",
      "\n",
      "1. **Accommodation**: Consider staying in areas like the City of London or Canary Wharf if your meetings are business-oriented. These areas have excellent transport links and plenty of business-friendly hotels like The Ned or Hilton London Canary Wharf.\n",
      "\n",
      "2. **Transport**: The London Underground (Tube) is efficient for getting around, but consider a contactless payment method or an Oyster card for convenience. For short distances, walking can be pleasant, especially in central areas.\n",
      "\n",
      "3. **Dining**: If you're looking to impress clients or colleagues, try dining at places like The Ivy or Hawksmoor for a classic British dining experience. For more casual meetings, Dishoom offers a lively atmosphere with delicious Indian cuisine.\n",
      "\n",
      "4. **Workspaces**: If you need a quiet place to work or hold meetings, check out coworking spaces like WeWork or The Office Group, which have locations across the city.\n",
      "\n",
      "5. **Leisure**: If you have some downtime, consider visiting the British Museum or taking a stroll in Hyde Park. Both are great ways to unwind and experience a bit of London.\n",
      "\n",
      "If you need more specific recommendations or have particular interests, feel free to ask!\n",
      "\n",
      "User: I need recommendations for fish and chips restaurants near London Bridge cause I love the taste!\n",
      "Assistant: Hi Suresh! That sounds exciting. For your business trip to London, here are a few tips and recommendations:\n",
      "\n",
      "1. **Accommodation**: Consider staying in areas like the City of London or Canary Wharf if your meetings are business-oriented. These areas have excellent transport links and plenty of business-friendly hotels like The Ned or Hilton London Canary Wharf.\n",
      "\n",
      "2. **Transport**: The London Underground (Tube) is efficient for getting around, but consider a contactless payment method or an Oyster card for convenience. For short distances, walking can be pleasant, especially in central areas.\n",
      "\n",
      "3. **Dining**: If you're looking to impress clients or colleagues, try dining at places like The Ivy or Hawksmoor for a classic British dining experience. For more casual meetings, Dishoom offers a lively atmosphere with delicious Indian cuisine.\n",
      "\n",
      "4. **Workspaces**: If you need a quiet place to work or hold meetings, check out coworking spaces like WeWork or The Office Group, which have locations across the city.\n",
      "\n",
      "5. **Leisure**: If you have some downtime, consider visiting the British Museum or taking a stroll in Hyde Park. Both are great ways to unwind and experience a bit of London.\n",
      "\n",
      "If you need more specific recommendations or have particular interests, feel free to ask!\n",
      "\n",
      "User: I need recommendations for fish and chips restaurants near London Bridge cause I love the taste!\n",
      "No relevant memories found\n",
      "No relevant memories found\n",
      "Assistant: Hi there! If you're near London Bridge and craving fish and chips, here are some great recommendations:\n",
      "\n",
      "1. **Fish! Borough Market** - Located in the heart of Borough Market, Fish! offers high-quality fish and chips with a variety of fresh fish options. It's a lively spot with a great atmosphere.\n",
      "\n",
      "2. **Golden Hinde** - Just a short walk away, this traditional fish and chip shop is known for its crispy batter and generous portions. It's a cozy and casual spot perfect for a quick meal.\n",
      "\n",
      "3. **Poppies Fish & Chips** - Although it's slightly further away in Spitalfields, Poppies is worth the journey. Known for its vintage decor and award-winning fish and chips, it's a London favorite.\n",
      "\n",
      "Enjoy your meal near London Bridge, and let me know if you need further recommendations!\n",
      "\n",
      "\n",
      "===== STORED MEMORIES (4) =====\n",
      "1. Planning a business trip to London next month for about 5 days\n",
      "2. Name is Suresh\n",
      "3. Needs recommendations for fish and chips restaurants near London Bridge\n",
      "4. Loves the taste of fish and chips\n",
      "==============================\n",
      "\n",
      "Assistant: Hi there! If you're near London Bridge and craving fish and chips, here are some great recommendations:\n",
      "\n",
      "1. **Fish! Borough Market** - Located in the heart of Borough Market, Fish! offers high-quality fish and chips with a variety of fresh fish options. It's a lively spot with a great atmosphere.\n",
      "\n",
      "2. **Golden Hinde** - Just a short walk away, this traditional fish and chip shop is known for its crispy batter and generous portions. It's a cozy and casual spot perfect for a quick meal.\n",
      "\n",
      "3. **Poppies Fish & Chips** - Although it's slightly further away in Spitalfields, Poppies is worth the journey. Known for its vintage decor and award-winning fish and chips, it's a London favorite.\n",
      "\n",
      "Enjoy your meal near London Bridge, and let me know if you need further recommendations!\n",
      "\n",
      "\n",
      "===== STORED MEMORIES (4) =====\n",
      "1. Planning a business trip to London next month for about 5 days\n",
      "2. Name is Suresh\n",
      "3. Needs recommendations for fish and chips restaurants near London Bridge\n",
      "4. Loves the taste of fish and chips\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results': [{'id': '3bab7819-17ef-4617-858e-abf6181f7258',\n",
       "   'memory': 'Planning a business trip to London next month for about 5 days',\n",
       "   'hash': '031c26def9826fc727a9376b558310ec',\n",
       "   'metadata': None,\n",
       "   'created_at': '2025-06-04T22:23:20.001106-07:00',\n",
       "   'updated_at': None,\n",
       "   'user_id': 'suresh_london_2025'},\n",
       "  {'id': 'ab642a64-3f4d-4c58-9352-d5b62d4b7922',\n",
       "   'memory': 'Name is Suresh',\n",
       "   'hash': '1afd89fe2fb284397171eaab71ec42c1',\n",
       "   'metadata': None,\n",
       "   'created_at': '2025-06-04T22:23:19.730070-07:00',\n",
       "   'updated_at': None,\n",
       "   'user_id': 'suresh_london_2025'},\n",
       "  {'id': 'ac063b30-e6db-412b-9a25-9a09f0e13f56',\n",
       "   'memory': 'Needs recommendations for fish and chips restaurants near London Bridge',\n",
       "   'hash': '1052f62dd8cb41ece8e968ce0c604aaf',\n",
       "   'metadata': None,\n",
       "   'created_at': '2025-06-04T22:23:26.382988-07:00',\n",
       "   'updated_at': None,\n",
       "   'user_id': 'suresh_london_2025'},\n",
       "  {'id': '5f1617f0-5a1b-4eb0-b78f-aca5c3f9cbbc',\n",
       "   'memory': 'Loves the taste of fish and chips',\n",
       "   'hash': 'da224e5a24455930584bf252d46e5fc9',\n",
       "   'metadata': None,\n",
       "   'created_at': '2025-06-04T22:23:26.628313-07:00',\n",
       "   'updated_at': None,\n",
       "   'user_id': 'suresh_london_2025'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create travel assistant for a user\n",
    "assistant = TravelAssistant(user_id=\"suresh_london_2025\")\n",
    "\n",
    "# First interaction - Initial inquiry\n",
    "query1 = \"Hi, my name is Suresh. I'm planning a business trip to London next month for about 5 days.\"\n",
    "print(f\"User: {query1}\")\n",
    "response1 = assistant.get_response(query1, memory_context=False)  # No memories yet\n",
    "print(f\"Assistant: {response1}\\n\")\n",
    "\n",
    "# Second interaction - Specific question about fish and chips\n",
    "query2 = \"I need recommendations for fish and chips restaurants near London Bridge cause I love the taste!\"\n",
    "print(f\"User: {query2}\")\n",
    "response2 = assistant.get_response(query2)  # Should use memory context\n",
    "print(f\"Assistant: {response2}\\n\")\n",
    "\n",
    "# Verify what memories have been stored\n",
    "assistant.verify_memories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9f1bc",
   "metadata": {},
   "source": [
    "This demonstration shows how the assistant:\n",
    "\n",
    "1. Stores Suresh’s name and travel plans from the first interaction\n",
    "2. Remembers these details in the second interaction\n",
    "3. Uses the memory context to provide a personalized response\n",
    "\n",
    "**Searching for Specific Preferences**\n",
    "\n",
    "You can also directly search for specific user preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "501fe2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 relevant memories:\n",
      "1. Needs recommendations for fish and chips restaurants near London Bridge (Score: 0.6556)\n",
      "2. Loves the taste of fish and chips (Score: 0.6482)\n",
      "3. Planning a business trip to London next month for about 5 days (Score: 0.5847)\n"
     ]
    }
   ],
   "source": [
    "search_query = \"What are Farzad's preferences for food in London?\"\n",
    "search_results = assistant.memory.search(search_query, user_id=\"suresh_london_2025\")\n",
    "print(f\"Found {len(search_results['results'])} relevant memories:\")\n",
    "for i, result in enumerate(search_results['results'][:3], 1):\n",
    "    print(f\"{i}. {result['memory']} (Score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69c026",
   "metadata": {},
   "source": [
    "This might return results like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104dfce",
   "metadata": {},
   "source": [
    "Found 3 relevant memories:\n",
    "1. Name is Suresh (Score: 0.6696)\n",
    "2. Needs recommendations for fish and chips restaurants near London Bridge (Score: 0.6564)\n",
    "3. Loves the taste of fish and chips (Score: 0.6324)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7183df",
   "metadata": {},
   "source": [
    "**The Power of Persistent Memory**\n",
    "\n",
    "The key advantage of this approach is that the assistant maintains context across multiple interactions. By leveraging Mem0 with Azure AI services, we’ve created a system that:\n",
    "\n",
    "1. Remembers user details: The assistant stores information like names, preferences, and travel plans\n",
    "2. Personalizes responses: By retrieving relevant memories, the assistant can refer to the user by name and tailor recommendations\n",
    "3. Improves over time: As more interactions occur, the system builds a more comprehensive understanding of the user\n",
    "This persistent memory dramatically improves the user experience by eliminating the need to repeat information in every conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5afada9",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Integrating Mem0 with Azure AI services opens up a world of possibilities for creating more personalized and context-aware AI applications. By maintaining user memories across interactions, we can build assistants that feel more intelligent and responsive to user needs.\n",
    "\n",
    "This tutorial has shown you how to:\n",
    "\n",
    "* Configure Mem0 with Azure AI Search and Azure OpenAI\n",
    "* Store and retrieve different types of memories\n",
    "* Build a practical travel assistant that remembers user preferences\n",
    "As you implement this in your own applications, consider the different types of memories you might want to store and how they can be used to enhance user experiences. With Mem0’s flexible memory system, you can create AI applications that truly understand and adapt to individual users over time.\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "* Explore using different types of metadata to categorize memories\n",
    "* Implement memory expiration or importance scoring\n",
    "* Combine memories with other Azure services like Azure AI Services for more advanced features\n",
    "For more information on Mem0 and its capabilities, visit the Mem0 documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
